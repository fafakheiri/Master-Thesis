# General (hyper)parameters
params:
  seed: 777
  do_train: True
  do_eval: True
  do_predict: True
  src: en_XX # See https://huggingface.co/facebook/mbart-large-50
  tgt: fa_IR # See https://huggingface.co/facebook/mbart-large-50
  lower_case: True # Tokenizer
  normalization: True # Tokenizer
  checkpoint: facebook/mbart-large-50
  max_len: 20
  # dataloader (bs = batch size)
  train_bs: 16 
  dev_bs: 16 
  test_bs: 16
  # bs per device
  device_train_bs: 16
  device_eval_bs: 16
  epoch: 3.5
   # log, save, and evaluate every n steps
  logging_step: 1000
  save_steps: 1000
  eval_steps: 1000
  save: 30
  early_stop: 4
  weight_decay: 0
  warmup_steps: 0
  fp16: False # Only can be used on CUDA devices
  lr: 1e-4
  evaluation: steps
  best_model: True
  optim: adamw_torch  # adafactor, adamw_torch default:adamw_hf
  hidden_dropout_prob: 0.1
  # eval metric
  metric_best_model: eval_bleu
  predict_with_generate: True # Otherwise you get: out of range integral type conversion attempted
  use_mps_device: False # Using Apple Silicon chip
# Dataset setup
dataset:
  train_path: '/home/u770766/final_augment/train_data.csv'
  dev_path: '/home/u770766/final_augment/dev_data.csv'
  test_path: '/home/u770766/final_augment/test_data.csv'
  predict_path: '/home/u770766/final_augment/250-final.txt' # Inference
# Splitter setup
splitter:
  active: True
  path: '/home/u770766/final_augment/250-final.txt'
  path2: '/home/u770766/final_augment/aug_100000.txt'
  split: 0.2
# MLFlow config
mlflow:
  exp_name: sample-augmented25-manual
  params: "_1"
MT:
  do_train: False
  do_eval: False
  do_predict: True
  train_path: '/home/u770766/final_augment/train_data.csv'
  dev_path: '/home/u770766/final_augment/dev_data.csv'
  test_path: '/home/u770766/final_augment/test_data.csv'
  predict_with_generate: True # Otherwise you get: out of range integral type conversion attempted
  src: en_XX 
  tgt: fa_IR
  checkpoint: facebook/mbart-large-50 #facebook/mbart-large-50